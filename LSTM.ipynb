{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8S5LiYz6wjax",
    "outputId": "1544a153-4ea6-4508-a601-8742dd42d332"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install gensim openpyxl nltk rouge-score bert_score tqdm --quiet\n",
    "\n",
    "# Download necessary NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LszFKDxgwt4u",
    "outputId": "6379a09d-e4ba-45bd-e29f-f2d68adb47fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Step 1: Loading datasets...\n",
      "   â†ª df_train shape: (1000, 3)\n",
      "   â†ª df_val shape: (50, 5)\n",
      "   â†ª df_test shape: (100, 3)\n",
      "ğŸ”¹ Step 2: Cleaning text and adding SOS/EOS tokens...\n",
      "Sample clean_summary with SOS/EOS: sos who manufactures cetirizine? eos\n",
      "Tokenized summary: ['sos', 'who', 'manufactures', 'cetirizine', '?', 'eos']\n",
      "Sample clean_summary with SOS/EOS: sos should i leave a meniscus tear untreated if it does not cause problems? eos\n",
      "Tokenized summary: ['sos', 'should', 'i', 'leave', 'a', 'meniscus', 'tear', 'untreated', 'if', 'it', 'does', 'not', 'cause', 'problems', '?', 'eos']\n",
      "Sample clean_summary with SOS/EOS: sos how can i get rid of a lower lip birthmark permanently? eos\n",
      "Tokenized summary: ['sos', 'how', 'can', 'i', 'get', 'rid', 'of', 'a', 'lower', 'lip', 'birthmark', 'permanently', '?', 'eos']\n",
      "   â†ª Sample cleaned question: subject who and where to get cetirizine d message i needwant to know who manufscturs cetirizine my walmart is looking for a new supply and are not getting the recent\n",
      "   â†ª Sample tokenized question: ['subject', 'who', 'and', 'where', 'to', 'get', 'cetirizine', 'd', 'message', 'i', 'needwant', 'to', 'know', 'who', 'manufscturs', 'cetirizine', 'my', 'walmart', 'is', 'looking', 'for', 'a', 'new', 'supply', 'and', 'are', 'not', 'getting', 'the', 'recent']\n",
      "   â†ª Sample cleaned summary (with sos/eos): sos who manufactures cetirizine? eos\n",
      "   â†ª Sample tokenized summary: ['sos', 'who', 'manufactures', 'cetirizine', '?', 'eos']\n",
      "ğŸ”¹ Step 3: Load or Train Word2Vec embeddings...\n",
      "   âœ… Loading frozen Word2Vec model...\n",
      "   â†ª Word2Vec vocabulary size: 8243\n",
      "ğŸ”¹ Step 4: Tokenizing and padding sequences...\n",
      "   â†ª Tokenizer vocab size: 8222\n",
      "   â†ª Top 10 words: [('<OOV>', 1), ('i', 2), ('the', 3), ('and', 4), ('to', 5), ('is', 6), ('a', 7), ('for', 8), ('my', 9), ('of', 10)]\n",
      "\n",
      "ğŸ” Checking train set before padding...\n",
      "   ğŸ”¸ Total summaries: 1000\n",
      "   ğŸ”¸ Start with SOS: 1000\n",
      "   ğŸ”¸ Contain EOS anywhere: 1000\n",
      "   ğŸ”¸ EOS at END before fixing: 1000\n",
      "   ğŸ”¸ Sample summary token IDs (first 2):\n",
      "      [11, 74, 2798, 2073, 1, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     â†ª SOS position: 0, EOS position: 5\n",
      "      [11, 74, 2798, 2075, 1, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     â†ª SOS position: 0, EOS position: 5\n",
      "\n",
      "ğŸ” Checking val set before padding...\n",
      "   ğŸ”¸ Total summaries: 50\n",
      "   ğŸ”¸ Start with SOS: 50\n",
      "   ğŸ”¸ Contain EOS anywhere: 50\n",
      "   ğŸ”¸ EOS at END before fixing: 50\n",
      "   ğŸ”¸ Sample summary token IDs (first 2):\n",
      "      [11, 96, 2, 1249, 7, 1367, 1099, 978, 31, 17, 80, 30, 119, 210, 1, 12, 0, 0, 0, 0]\n",
      "     â†ª SOS position: 0, EOS position: 15\n",
      "      [11, 35, 16, 2, 43, 7, 497, 74, 70, 182, 9, 2806, 228, 1, 12, 0, 0, 0, 0, 0]\n",
      "     â†ª SOS position: 0, EOS position: 14\n",
      "\n",
      "ğŸ” Checking test set before padding...\n",
      "   ğŸ”¸ Total summaries: 100\n",
      "   ğŸ”¸ Start with SOS: 100\n",
      "   ğŸ”¸ Contain EOS anywhere: 100\n",
      "   ğŸ”¸ EOS at END before fixing: 100\n",
      "   ğŸ”¸ Sample summary token IDs (first 2):\n",
      "      [11, 35, 16, 2, 56, 502, 10, 7, 365, 2450, 2750, 2429, 1, 12, 0, 0, 0, 0, 0, 0]\n",
      "     â†ª SOS position: 0, EOS position: 13\n",
      "      [11, 6, 1066, 4079, 457, 8, 206, 1, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     â†ª SOS position: 0, EOS position: 8\n",
      "   â†ª X_train shape: (1000, 50)\n",
      "   â†ª y_train shape: (1000, 20)\n",
      "   â†ª Sample X_train[0]: [  20   74    4   52    5   56 2073  886   19    2 4163    5   49   74\n",
      " 4164 2073    9 4165    6  135    8    7  213 2074    4   18   30  211\n",
      "    3  812    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "   â†ª Sample y_train[0]: [  11   74 2798 2073    1   12    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "\n",
      "ğŸ” Quality Check on y_train:\n",
      "   - Total summaries: 1000\n",
      "   - Start with SOS: 1000\n",
      "   - Contain EOS: 1000\n",
      "   - EOS at end of sequence: 59\n",
      "   - Avg summary length: 12.89\n",
      "   - Max summary length allowed: 20\n",
      "ğŸ”¹ Step 5: Building embedding matrix from Word2Vec...\n",
      "   â†ª Embedding matrix shape: (8222, 128)\n",
      "âœ… Preprocessing complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessingword2vec import load_and_preprocess_data\n",
    "\n",
    "# âœ… File paths\n",
    "train_path = \"/content/MeQSum_ACL2019_BenAbacha_Demner-Fushman.xlsx\"\n",
    "val_path   = \"/content/MEDIQA2021-Task1-QuestionSummarization-ValidationSet.xlsx\"\n",
    "test_path  = \"/content/MEDIQA2021-Task1-TestSet-ReferenceSummaries.xlsx\"\n",
    "w2v_path   = \"/content/w2v_frozen.model\"  # ensure this is uploaded\n",
    "\n",
    "# âœ… Load and preprocess data\n",
    "data = load_and_preprocess_data(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    w2v_path=w2v_path,      # match the function signature\n",
    "    max_len_q=50,\n",
    "    max_len_s=20,\n",
    "    embedding_dim=128\n",
    ")\n",
    "\n",
    "# âœ… Unpack processed data\n",
    "X_train          = data[\"X_train\"]\n",
    "y_train          = data[\"y_train\"]\n",
    "X_val            = data[\"X_val\"]\n",
    "y_val            = data[\"y_val\"]\n",
    "X_test           = data[\"X_test\"]\n",
    "y_test           = data[\"y_test\"]\n",
    "tokenizer        = data[\"tokenizer\"]\n",
    "vocab_size       = data[\"vocab_size\"]\n",
    "max_len_q        = data[\"max_len_q\"]\n",
    "max_len_s        = data[\"max_len_s\"]\n",
    "embedding_matrix = data[\"embedding_matrix\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "r61N_2lGAK2C",
    "outputId": "5ab80ccc-a0aa-4e13-b80e-a406694e4719"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_22        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,416</span> â”‚ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_23        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,416</span> â”‚ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> â”‚ embedding_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> â”‚ embedding_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ attention_score     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)               â”‚                   â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attention_score[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ context_vector      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attention_weightâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)               â”‚                   â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_concat_conâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ context_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed_11 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ decoder_concat_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ final_output        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8222</span>)  â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,113,054</span> â”‚ time_distributedâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_22        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚  \u001b[38;5;34m1,052,416\u001b[0m â”‚ encoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_23        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚  \u001b[38;5;34m1,052,416\u001b[0m â”‚ decoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m), â”‚    \u001b[38;5;34m394,240\u001b[0m â”‚ embedding_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m), â”‚    \u001b[38;5;34m394,240\u001b[0m â”‚ embedding_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ attention_score     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDot\u001b[0m)               â”‚                   â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attention_score[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ context_vector      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attention_weightâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDot\u001b[0m)               â”‚                   â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_concat_conâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ context_vector[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed_11 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ decoder_concat_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)   â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ final_output        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m8222\u001b[0m)  â”‚  \u001b[38;5;34m2,113,054\u001b[0m â”‚ time_distributedâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,137,694</span> (19.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,137,694\u001b[0m (19.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,032,862</span> (11.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,032,862\u001b[0m (11.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,104,832</span> (8.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,104,832\u001b[0m (8.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, Dot, Activation, TimeDistributed\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "latent_dim = 256\n",
    "embedding_dim = 128  # must match your embedding_matrix dimension\n",
    "\n",
    "# ----- ENCODER -----\n",
    "encoder_inputs = Input(shape=(max_len_q,), name=\"encoder_input\")\n",
    "enc_emb = Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False,\n",
    "    mask_zero=False         # disable masking to avoid BroadcastTo errors\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(\n",
    "    latent_dim,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    dropout=0.3,\n",
    "    recurrent_dropout=0.3,\n",
    "    name=\"encoder_lstm\"\n",
    ")\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# ----- DECODER -----\n",
    "decoder_inputs = Input(shape=(max_len_s - 1,), name=\"decoder_input\")\n",
    "dec_emb = Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False,\n",
    "    mask_zero=False         # also disable masking here\n",
    ")(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(\n",
    "    latent_dim,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    dropout=0.3,            # disable CuDNN path\n",
    "    recurrent_dropout=0.3,  # disable CuDNN path\n",
    "    implementation=1,       # force generic TF LSTM\n",
    "    name=\"decoder_lstm\"\n",
    ")\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# ----- ATTENTION -----\n",
    "score = Dot(axes=[2, 2], name=\"attention_score\")([decoder_outputs, encoder_outputs])\n",
    "attention_weights = Activation('softmax', name=\"attention_weights\")(score)\n",
    "context_vector = Dot(axes=[2, 1], name=\"context_vector\")([attention_weights, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1, name=\"decoder_concat_context\")(\n",
    "    [context_vector, decoder_outputs]\n",
    ")\n",
    "\n",
    "# ğŸ” Optional Dense Layer for richer representations\n",
    "intermediate = TimeDistributed(Dense(256, activation='tanh'))(decoder_combined_context)\n",
    "output = Dense(vocab_size, activation='softmax', name=\"final_output\")(intermediate)\n",
    "\n",
    "# ğŸ”§ Compile Model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# ğŸ¯ Attention Model for visualization\n",
    "attention_model = Model(\n",
    "    [encoder_inputs, decoder_inputs],\n",
    "    [output, attention_weights]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "At2UurcM73WI"
   },
   "outputs": [],
   "source": [
    "# Correct reverse lookup and token IDs\n",
    "reverse_tokenizer = {v: k for k, v in tokenizer.word_index.items()}\n",
    "sos_token = tokenizer.word_index.get('sos', tokenizer.word_index.get('SOS'))\n",
    "eos_token = tokenizer.word_index.get('eos', tokenizer.word_index.get('EOS'))\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Prepare decoder input of integer token IDs\n",
    "    decoder_input = np.zeros((1, max_len_s - 1), dtype=int)\n",
    "    decoder_input[0, 0] = sos_token\n",
    "\n",
    "    output_seq = []\n",
    "    for i in range(max_len_s - 1):\n",
    "        # Predict next token probabilities\n",
    "        preds = model.predict([input_seq, decoder_input], verbose=0)\n",
    "        pred_id = np.argmax(preds[0, i])\n",
    "        word = reverse_tokenizer.get(pred_id, '')\n",
    "\n",
    "        if word == 'eos':\n",
    "            break\n",
    "        if word.lower() not in ('sos', 'eos', '<OOV>', ''):\n",
    "            output_seq.append(word)\n",
    "\n",
    "        # Feed predicted ID into next timestep\n",
    "        decoder_input[0, i] = pred_id\n",
    "\n",
    "    return ' '.join(output_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo3gg0bx76hK",
    "outputId": "0626f879-4f25-4dcb-e695-642ce8a57da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Validation Perplexity: 8295.27\n",
      "\n",
      "\n",
      "BERTScore Results:\n",
      "Precision : 0.5212\n",
      "Recall    : 0.2301\n",
      "F1 Score  : 0.3785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# Correct reverse lookup and token IDs\n",
    "reverse_tokenizer = {v: k for k, v in tokenizer.word_index.items()}\n",
    "sos_token = tokenizer.word_index.get('sos', tokenizer.word_index.get('SOS'))\n",
    "eos_token = tokenizer.word_index.get('eos', tokenizer.word_index.get('EOS'))\n",
    "\n",
    "def decode_sequence_beam(input_seq, beam_width=5):\n",
    "    # Each candidate: (token list, score, decoder_input array)\n",
    "    sequences = [[[], 0.0, np.zeros((1, max_len_s - 1), dtype=int)]]\n",
    "    sequences[0][2][0, 0] = sos_token\n",
    "\n",
    "    for _ in range(max_len_s - 2):\n",
    "        all_candidates = []\n",
    "        for seq, score, decoder_input in sequences:\n",
    "            preds = model.predict([input_seq, decoder_input], verbose=0)\n",
    "            prob_dist = preds[0, len(seq)]\n",
    "            top_ids = np.argsort(prob_dist)[-beam_width:]\n",
    "\n",
    "            for tok_id in top_ids:\n",
    "                word = reverse_tokenizer.get(tok_id, '')\n",
    "                if word.lower() in ('sos', '<OOV>', ''):\n",
    "                    continue\n",
    "                new_seq = seq + [word]\n",
    "                # length penalty\n",
    "                new_score = (score - np.log(prob_dist[tok_id] + 1e-10)) / (len(seq) + 1)\n",
    "                new_decoder_input = decoder_input.copy()\n",
    "                if len(seq) + 1 < max_len_s - 1:\n",
    "                    new_decoder_input[0, len(seq) + 1] = tok_id\n",
    "                all_candidates.append([new_seq, new_score, new_decoder_input])\n",
    "\n",
    "        # keep best beams\n",
    "        sequences = sorted(all_candidates, key=lambda tup: tup[1])[:beam_width]\n",
    "\n",
    "        # stop if all sequences have ended\n",
    "        if all('eos' in seq for seq, _, _ in sequences):\n",
    "            break\n",
    "\n",
    "    # choose best sequence and strip eos if present\n",
    "    final_seq = sequences[0][0]\n",
    "    if 'eos' in final_seq:\n",
    "        final_seq = final_seq[:final_seq.index('eos')]\n",
    "    return ' '.join(w for w in final_seq if w.lower() not in ('sos', '<OOV>'))\n",
    "\n",
    "# ğŸ“Š Evaluation Setup\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "smoothie = SmoothingFunction().method4\n",
    "refs, preds = [], []\n",
    "\n",
    "# ğŸ§  Perplexity\n",
    "val_loss = model.evaluate([X_val, decoder_input_val], decoder_target_val, verbose=0)[0]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"ğŸ§  Validation Perplexity: {perplexity:.2f}\\n\")\n",
    "\n",
    "# ğŸ” Sample Evaluation\n",
    "for idx in range(10):\n",
    "    input_seq = X_val[idx:idx+1]\n",
    "    ref_ids   = y_val[idx]\n",
    "\n",
    "    reference = [\n",
    "        reverse_tokenizer.get(tok, '')\n",
    "        for tok in ref_ids\n",
    "        if tok not in (0, sos_token, eos_token)\n",
    "    ]\n",
    "    reference = [w for w in reference if w]\n",
    "\n",
    "    prediction = decode_sequence_beam(input_seq, beam_width=5)\n",
    "\n",
    "# ğŸ“ BERTScore\n",
    "print(\"\\nBERTScore Results:\")\n",
    "print(f\"Precision : {abs(P.mean().item()):.4f}\")\n",
    "print(f\"Recall    : {abs(R.mean().item()):.4f}\")\n",
    "print(f\"F1 Score  : {abs(F1.mean().item()):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
